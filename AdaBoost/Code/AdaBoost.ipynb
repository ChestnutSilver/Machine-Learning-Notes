{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集：《统计学习方法》数据\n",
    "\n",
    "训练集数量：10\n",
    "\n",
    "测试集数量：0\n",
    "\n",
    "层数：3\n",
    "\n",
    "运行结果：正确率：100%；运行时长：<1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(fileName):\n",
    "    '''\n",
    "    加载文件\n",
    "    :param fileName:要加载的文件路径\n",
    "    :return: 数据集和标签集\n",
    "    '''\n",
    "    #存放数据及标记\n",
    "    dataArr = []; labelArr = []\n",
    "    #读取文件\n",
    "    fr = open(fileName)\n",
    "    #遍历文件中的每一行\n",
    "    for line in fr.readlines():\n",
    "        #获取当前行，并按“，”切割成字段放入列表中\n",
    "        #strip：去掉每行字符串首尾指定的字符（默认空格或换行符）\n",
    "        #split：按照指定的字符将字符串切割成每个字段，返回列表形式\n",
    "        curLine = line.strip().split(',')\n",
    "        #将curLine[1]数据放入数据集中, 将原先字符串形式的数据转换为整型\n",
    "        dataArr.append(int(curLine[1]))\n",
    "\n",
    "        #将curLine[0]标记信息放入标记集中, 放入的同时将标记转换为整型\n",
    "        #二分类任务, 标签1设置为1，反之为-1\n",
    "        if int(curLine[0]) == 1:\n",
    "            labelArr.append(1)\n",
    "        else:\n",
    "            labelArr.append(-1)\n",
    "    #返回数据集和标记\n",
    "    return dataArr, labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_e_Gx(trainDataArr, trainLabelArr, n, div, rule, D):\n",
    "    '''\n",
    "    计算分类错误率\n",
    "    :param trainDataArr: 训练数据集数组\n",
    "    :param trainLabelArr: 训练标签集数组\n",
    "    :param n: 要操作的特征\n",
    "    :param div: 划分点\n",
    "    :param rule: 正反例标签\n",
    "    :param D: 权值分布D\n",
    "    :return: 预测结果，分类误差率\n",
    "    '''\n",
    "    #初始化分类误差率为0\n",
    "    e = 0\n",
    "    #训练数据数组\n",
    "    x = trainDataArr\n",
    "    #同样将标签也转换成数组格式，x和y的转换只是单纯为了提高运行速度\n",
    "    #测试过相对直接操作而言性能提升很大\n",
    "    y = trainLabelArr\n",
    "    predict = []\n",
    "\n",
    "    #依据小于和大于的标签依据实际情况会不同，在这里直接进行设置\n",
    "    if rule == 'LisOne':    L = 1; H = -1\n",
    "    else:                   L = -1; H = 1\n",
    "\n",
    "    #遍历所有样本的特征m\n",
    "    for i in range(trainDataArr.shape[0]):\n",
    "        if x[i] < div:\n",
    "            #如果小于划分点，则预测为L\n",
    "            #如果设置小于div为1，那么L就是1，\n",
    "            #如果设置小于div为-1，L就是-1\n",
    "            predict.append(L)\n",
    "            #如果预测错误，分类错误率要加上该分错的样本的权值（8.1式）\n",
    "            if y[i] != L: e += D[i]\n",
    "        elif x[i] >= div:\n",
    "            #与上面思想一样\n",
    "            predict.append(H)\n",
    "            if y[i] != H: e += D[i]\n",
    "    #返回预测结果和分类错误率e\n",
    "    #预测结果其实是为了后面做准备的，在算法8.1第四步式8.4中exp内部有个Gx，要用在那个地方\n",
    "    #以此来更新新的D\n",
    "    return np.array(predict), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSigleBoostingTree(trainDataArr, trainLabelArr, D):\n",
    "    '''\n",
    "    创建单层提升树\n",
    "    :param trainDataArr: 训练数据集数组\n",
    "    :param trainLabelArr: 训练标签集数组\n",
    "    :param D: 算法8.1中的D\n",
    "    :return: 创建的单层提升树\n",
    "    '''\n",
    "\n",
    "    #获得样本数目及特征数量, 本例特征数量为1\n",
    "    n = 1\n",
    "    #单层树的字典，用于存放当前层提升树的参数\n",
    "    #也可以认为该字典代表了一层提升树\n",
    "    sigleBoostTree = {}\n",
    "    #初始化分类误差率，分类误差率在算法8.1步骤（2）（b）有提到\n",
    "    #误差率最高也只能100%，因此初始化为1\n",
    "    sigleBoostTree['e'] = 1\n",
    "\n",
    "    #对每一个特征进行遍历，寻找用于划分的最合适的特征；因为本例只有一个特征，可以忽略此循环\n",
    "    for i in range(n):\n",
    "        #因为特征的取值范围在0-9，因此分切分时分为下面几种取值进行切割\n",
    "        for div in [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]:\n",
    "            #在单个特征内对正反例进行划分时，有两种情况：\n",
    "            #可能是小于某值的为1，大于某值得为-1，也可能小于某值得是-1，反之为1\n",
    "            #因此在寻找最佳提升树的同时对于两种情况也需要遍历运行\n",
    "            #LisOne：Low is one：小于某值得是1\n",
    "            #HisOne：High is one：大于某值得是1\n",
    "            for rule in ['LisOne', 'HisOne']:\n",
    "                #按照第i个特征，以值div进行切割，进行当前设置得到的预测和分类错误率\n",
    "                #【4】估计基学习器ht的误差\n",
    "                Gx, e = calc_e_Gx(trainDataArr, trainLabelArr, i, div, rule, D)\n",
    "                #如果分类错误率e小于当前最小的e，那么将它作为最小的分类错误率保存（记录最小分类错误率的目的是为了找到符合要求的切割阈值）\n",
    "                #【5】基学习器均满足e<0.5，代码中省略了这一判定\n",
    "                if e < sigleBoostTree['e']:\n",
    "                    sigleBoostTree['e'] = e\n",
    "                    #同时也需要存储最优划分点、划分规则、预测结果、特征索引\n",
    "                    #以便进行D更新和后续预测使用\n",
    "                    sigleBoostTree['div'] = div\n",
    "                    sigleBoostTree['rule'] = rule\n",
    "                    sigleBoostTree['Gx'] = Gx\n",
    "                    sigleBoostTree['feature'] = i\n",
    "    #返回单层的提升树\n",
    "    return sigleBoostTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBosstingTree(trainDataList, trainLabelList, treeNum = 50):\n",
    "    '''\n",
    "    创建提升树\n",
    "    创建算法依据“8.1.2 AdaBoost算法” 算法8.1\n",
    "    :param trainDataList: 训练数据集\n",
    "    :param trainLabelList: 训练测试集\n",
    "    :param treeNum: 树的层数\n",
    "    :return: 提升树\n",
    "    '''\n",
    "    #将数据和标签转化为数组形式\n",
    "    trainDataArr = np.array(trainDataList)\n",
    "    trainLabelArr = np.array(trainLabelList)\n",
    "    #每增加一层树后，当前最终预测结果列表\n",
    "    finallpredict = [0] * len(trainLabelArr)\n",
    "    #获得训练集数量\n",
    "    m = len(trainDataArr)\n",
    "\n",
    "    #【1】初始化样本权值分布\n",
    "    D = [1 / m] * m\n",
    "    #初始化提升树列表，每个位置为一层\n",
    "    tree = []\n",
    "    #【2】循环进行T轮训练（循环创建提升树）\n",
    "    #这里之所以叫“提升树”，是因为在本例中，AdaBoost算法使用的基分类器本质上是一个“决策树桩”\n",
    "    for i in range(treeNum):\n",
    "        #【3】基于分布Dt从数据集中训练出分类器，得到当前层的提升树\n",
    "        curTree = createSigleBoostingTree(trainDataArr, trainLabelArr, D)\n",
    "        #【6】确定基分类器的权重（当前层的alpha）\n",
    "        alpha = 1/2 * np.log((1 - curTree['e']) / curTree['e'])\n",
    "        #获得当前层的预测结果，用于下一步更新D\n",
    "        Gx = curTree['Gx']\n",
    "\n",
    "        #【7】更新样本分布，Zm是规范化因子，以确保D是一个分布\n",
    "        #D是一个行向量，由wmi元素组成，然后D中元素求和为Zm，Zm规范化因子使得D是一个分布\n",
    "        D = np.multiply(D, np.exp(-1 * alpha * np.multiply(trainLabelArr, Gx)))\n",
    "        Zm = sum(D)\n",
    "        D = D / Zm\n",
    "        \n",
    "        #在当前层参数中增加alpha参数，预测的时候需要用到\n",
    "        curTree['alpha'] = alpha\n",
    "        #将当前层添加到提升树索引中。\n",
    "        tree.append(curTree)\n",
    "\n",
    "        #-----以下代码用来辅助，可以去掉---------------\n",
    "        #将结果加上当前层乘以α，得到截至目前循环的输出预测\n",
    "        finallpredict += alpha * Gx\n",
    "        #计算当前最终预测输出与实际标签之间的误差\n",
    "        error = sum([1 for i in range(len(trainDataList)) if np.sign(finallpredict[i]) != trainLabelArr[i]])\n",
    "        #计算当前误差率\n",
    "        finallError = error / len(trainDataList)\n",
    "        #如果误差为0，提前退出即可，因为没有必要再计算了\n",
    "        if finallError == 0:\n",
    "            print(finallpredict)\n",
    "            print('iter:%d:%d, sigle error:%.4f, finall error:%.4f'%(i, treeNum, curTree['e'], finallError ))\n",
    "            return tree\n",
    "        #打印一些信息\n",
    "        print(finallpredict)\n",
    "        print('iter:%d:%d, sigle error:%.4f, finall error:%.4f'%(i, treeNum, curTree['e'], finallError ))\n",
    "    #返回整个提升树\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, div, rule, feature):\n",
    "    '''\n",
    "    输出单独层预测结果\n",
    "    :param x: 预测样本\n",
    "    :param div: 划分点\n",
    "    :param rule: 划分规则\n",
    "    :param feature: 进行操作的特征\n",
    "    :return:\n",
    "    '''\n",
    "    #依据划分规则定义小于及大于划分点的标签\n",
    "    if rule == 'LisOne':    L = 1; H = -1\n",
    "    else:                   L = -1; H = 1\n",
    "\n",
    "    #判断预测结果\n",
    "    if x < div: return L\n",
    "    else:   return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(testDataList, testLabelList, tree):\n",
    "    '''\n",
    "    测试\n",
    "    :param testDataList: 测试数据集\n",
    "    :param testLabelList: 测试标签集\n",
    "    :param tree: 提升树\n",
    "    :return: 准确率\n",
    "    '''\n",
    "    #错误率计数值\n",
    "    errorCnt = 0\n",
    "    #遍历每一个测试样本\n",
    "    for i in range(len(testDataList)):\n",
    "        #预测结果值，初始为0\n",
    "        result = 0\n",
    "        #依据算法8.1式8.6\n",
    "        #预测式子是一个求和式，对于每一层的结果都要进行一次累加\n",
    "        #遍历每层的树\n",
    "        for curTree in tree:\n",
    "            #获取该层参数\n",
    "            div = curTree['div']\n",
    "            rule = curTree['rule']\n",
    "            feature = curTree['feature']\n",
    "            alpha = curTree['alpha']\n",
    "            #将当前层结果加入预测中\n",
    "            result += alpha * predict(testDataList[i], div, rule, feature)\n",
    "        #预测结果取sign值，如果大于0 sign为1，反之为0\n",
    "        if np.sign(result) != testLabelList[i]: errorCnt += 1\n",
    "    #返回准确率\n",
    "    return 1 - errorCnt / len(testDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start read transSet\n"
     ]
    }
   ],
   "source": [
    "# 获取训练集\n",
    "print('start read transSet')\n",
    "trainDataList, trainLabelList = loadData('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, -1, -1, -1, 1, 1, 1, -1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start read testSet\n"
     ]
    }
   ],
   "source": [
    "# 获取测试集\n",
    "print('start read testSet')\n",
    "testDataList, testLabelList = loadData('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start init train\n",
      "[ 0.42364893  0.42364893  0.42364893 -0.42364893 -0.42364893 -0.42364893\n",
      " -0.42364893 -0.42364893 -0.42364893 -0.42364893]\n",
      "iter:0:40, sigle error:0.3000, finall error:0.3000\n",
      "[ 1.07329042  1.07329042  1.07329042  0.22599256  0.22599256  0.22599256\n",
      "  0.22599256  0.22599256  0.22599256 -1.07329042]\n",
      "iter:1:40, sigle error:0.2143, finall error:0.3000\n",
      "[ 0.32125172  0.32125172  0.32125172 -0.52604614 -0.52604614 -0.52604614\n",
      "  0.97803126  0.97803126  0.97803126 -0.32125172]\n",
      "iter:2:40, sigle error:0.1818, finall error:0.0000\n"
     ]
    }
   ],
   "source": [
    "# 创建提升树\n",
    "print('start init train')\n",
    "tree = createBosstingTree(trainDataList, trainLabelList, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'e': 0.30000000000000004,\n",
       "  'div': 2.5,\n",
       "  'rule': 'LisOne',\n",
       "  'Gx': array([ 1,  1,  1, -1, -1, -1, -1, -1, -1, -1]),\n",
       "  'feature': 0,\n",
       "  'alpha': 0.4236489301936017},\n",
       " {'e': 0.21428571428571427,\n",
       "  'div': 8.5,\n",
       "  'rule': 'LisOne',\n",
       "  'Gx': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1, -1]),\n",
       "  'feature': 0,\n",
       "  'alpha': 0.6496414920651304},\n",
       " {'e': 0.18181818181818185,\n",
       "  'div': 5.5,\n",
       "  'rule': 'HisOne',\n",
       "  'Gx': array([-1, -1, -1, -1, -1, -1,  1,  1,  1,  1]),\n",
       "  'feature': 0,\n",
       "  'alpha': 0.752038698388137}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to test\n",
      "the accuracy is:100 %\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "print('start to test')\n",
    "accuracy = model_test(trainDataList, trainLabelList, tree)\n",
    "print('the accuracy is:%d' % (accuracy * 100), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
